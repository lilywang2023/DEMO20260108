# imports
import os, sys

# third party imports
import numpy as np
import tensorflow as tf

assert tf.__version__.startswith('2.'), 'This tutorial assumes Tensorflow 2.0+'

import voxelmorph as vxm
import neurite as ne

# You should most often have this import together with all other imports at the top,
# but we include here here explicitly to show where data comes from
from tensorflow.keras.datasets import mnist

# load MNIST data.
# `mnist.load_data()` already splits our data into train and test.
(x_train_load, y_train_load), (x_test_load, y_test_load) = mnist.load_data()
# (x_train, y_train),  # è®­ç»ƒé›†ï¼š60,000 å¼ å›¾åƒ + æ ‡ç­¾
# (x_test, y_test)  # æµ‹è¯•é›†ï¼š10,000 å¼ å›¾åƒ + æ ‡ç­¾
# å˜é‡	     å½¢çŠ¶ï¼ˆshapeï¼‰	   æ•°æ®ç±»å‹	å«ä¹‰
# x_train	(60000, 28, 28)	    uint8	6 ä¸‡å¼  28Ã—28 åƒç´ çš„ç°åº¦å›¾ï¼ˆåƒç´ å€¼ 0â€“255ï¼‰
# y_train	(60000,)	        uint8	å¯¹åº”çš„æ ‡ç­¾ï¼ˆæ•°å­— 0â€“9ï¼‰
# x_test	(10000, 28, 28) 	uint8	1 ä¸‡å¼ æµ‹è¯•å›¾åƒ
# y_test	(10000,)	        uint8	æµ‹è¯•æ ‡ç­¾
# ç¬¬ 1 æ­¥ï¼šå‡½æ•°è¿”å›ä¸€ä¸ªåµŒå¥—å…ƒç»„
# result çš„ç»“æ„æ˜¯ï¼š ( (array_x_train, array_y_train), (array_x_test,  array_y_test) )
# ç¬¬ 2 æ­¥ï¼šç”¨åµŒå¥—å…ƒç»„è¿›è¡Œè§£åŒ…èµ‹å€¼
# (a, b), (c, d) = result

# Data
# ###########################################################################################################################################################################
print("---start to load data---")
digit_sel = 6

# extract only instances of the digit 5
x_train = x_train_load[y_train_load == digit_sel, ...]
y_train = y_train_load[y_train_load == digit_sel]
x_test = x_test_load[y_test_load == digit_sel, ...]
y_test = y_test_load[y_test_load == digit_sel]

# let's get some shapes to understand what we loaded.
print('shape of x_train: {}, y_train: {}'.format(x_train.shape, y_train.shape))

nb_val = 1000  # keep 1,000 subjects for validation
x_val = x_train[-nb_val:, ...]  # this indexing means "the last nb_val entries" of the zeroth axis
y_val = y_train[-nb_val:]
x_train = x_train[:-nb_val, ...]
y_train = y_train[:-nb_val]
print('shape of x_val: {}, y_val: {}'.format(x_val.shape, y_val.shape))
print('shape of x_train: {}, y_train: {}'.format(x_train.shape, y_train.shape))

# Visualize Data
# ###########################################################################################################################################################################
print("---start to visualize data---")
nb_vis = 5

# choose nb_vis sample indexes
idx = np.random.choice(x_train.shape[0], nb_vis, replace=False)
# aï¼šå¯é€‰å€¼èŒƒå›´ã€‚= x_train.shape[0]
# å¦‚æœ a æ˜¯ä¸€ä¸ªæ•´æ•°ï¼ˆå¦‚æœ¬ä¾‹ä¸­çš„ x_train.shape[0]ï¼‰ï¼Œåˆ™è¡¨ç¤ºä» 0 åˆ° a-1 çš„æ•´æ•°ä¸­é‡‡æ ·ã€‚
# å¦‚æœ a æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œåˆ™ä»è¯¥æ•°ç»„å…ƒç´ ä¸­é‡‡æ ·ã€‚
# sizeï¼ˆæ­¤å¤„ä¸º nb_visï¼‰ï¼šè¦é‡‡æ ·çš„æ ·æœ¬æ•°é‡ã€‚
# replace=Falseï¼šè¡¨ç¤ºæ— æ”¾å›æŠ½æ ·ï¼ˆå³ä¸é‡å¤ï¼‰ã€‚

example_digits = [f for f in x_train[idx, ...]]

print('idx=', idx)

# plot
# ne.plot.slices(example_digits, cmaps=['gray'], do_colorbars=True);

# fix data
x_train = x_train.astype('float') / 255
x_val = x_val.astype('float') / 255
x_test = x_test.astype('float') / 255

# verify
print('training maximum value', x_train.max())

# re-visualize
example_digits = [f for f in x_train[idx, ...]]

titles = [f for f in idx]
ne.plot.slices(example_digits, titles=titles, cmaps=['gray'], do_colorbars=True)

# å¡«å……è§„æ ¼
pad_amount = ((0, 0), (2, 2), (2, 2))

# fix data
x_train = np.pad(x_train, pad_amount, 'constant')
x_val = np.pad(x_val, pad_amount, 'constant')
x_test = np.pad(x_test, pad_amount, 'constant')
# np.pad(array, pad_width, mode='constant', constant_values=0)
# å„å‚æ•°è¯´æ˜ï¼š
# array	è¦å¡«å……çš„è¾“å…¥æ•°ç»„ï¼ˆå¦‚ x_trainï¼‰
# pad_width	æŒ‡å®šæ¯ä¸ªè½´ï¼ˆç»´åº¦ï¼‰å‰åè¦å¡«å……å¤šå°‘å…ƒç´ ï¼ˆå³ pad_amountï¼‰
# mode	å¡«å……æ–¹å¼ï¼Œå¦‚ 'constant'ã€'edge'ã€'reflect' ç­‰
# constant_valuesï¼ˆå¯é€‰ï¼‰	å½“ mode='constant' æ—¶ï¼ŒæŒ‡å®šå¡«å……çš„å¸¸æ•°å€¼ï¼Œé»˜è®¤ä¸º 0

# verify
print('shape of training data', x_train.shape)

# re-visualize
example_digits = [f for f in x_train[idx, ...]]
ne.plot.slices(example_digits, cmaps=['gray'], do_colorbars=True);

# CNN Model
# ################################################################################################################################################################################
# configure unet input shape (concatenation of moving and fixed images)
print("---start to set CNN Model---")
ndim = 2
unet_input_features = 2
# è¡¨ç¤º U-Net çš„è¾“å…¥é€šé“æ•°ï¼ˆinput channelsï¼‰ä¸º 2ã€‚
# åœ¨ å›¾åƒé…å‡†ä»»åŠ¡ä¸­ï¼Œé€šå¸¸å°† ä¸¤å¹…å›¾åƒæ‹¼æ¥ï¼ˆconcatenateï¼‰ä½œä¸ºè¾“å…¥ï¼š
# ç¬¬ 1 é€šé“ï¼šå›ºå®šå›¾åƒï¼ˆfixed imageï¼‰
# ç¬¬ 0 é€šé“ï¼šæµ®åŠ¨å›¾åƒï¼ˆmoving imageï¼‰
# å› æ­¤è¾“å…¥æ˜¯ä¸€ä¸ª (H, W, 2) çš„å¼ é‡ï¼ˆ2D æƒ…å†µä¸‹ï¼‰ã€‚
# ğŸ“Œ è¿™æ˜¯ VoxelMorph å…¸å‹çš„â€œè”åˆè¾“å…¥â€ç­–ç•¥ï¼šæŠŠ fixed + moving å›¾åƒå åœ¨ä¸€èµ·é€å…¥ç½‘ç»œï¼Œé¢„æµ‹å®ƒä»¬ä¹‹é—´çš„å½¢å˜åœºã€‚

inshape = (*x_train.shape[1:], unet_input_features)
# *æ˜¯è§£åŒ…å‡½æ•°çš„æ„æ€
print('inshape:', inshape)

# configure unet features
nb_features = [
    [32, 32, 32, 32],  # encoder features
    [32, 32, 32, 32, 32, 16]  # decoder features
]

# build model
unet = vxm.networks.Unet(inshape=inshape, nb_features=nb_features)
# åˆ›å»ºäº†ä¸€ä¸ªä¸“ä¸ºåŒ»å­¦å›¾åƒé…å‡†è®¾è®¡çš„ U-Net ç½‘ç»œï¼Œå…¶ä½œç”¨æ˜¯ï¼š
# æ¥æ”¶ä¸€å¯¹æ‹¼æ¥çš„ 2D/3D åŒ»å­¦å›¾åƒï¼Œè¾“å‡ºä¸€ä¸ª dense displacement fieldï¼ˆå¯†é›†å½¢å˜åœºï¼‰ï¼Œç”¨äºåç»­å›¾åƒ warpã€‚
# inshapeï¼šå®šä¹‰å›¾åƒç©ºé—´å°ºå¯¸ï¼ˆå¦‚ (128, 128)ï¼‰
# nb_featuresï¼šå®šä¹‰ç½‘ç»œæ¯å±‚çš„å·ç§¯é€šé“æ•°ï¼Œæ§åˆ¶æ¨¡å‹å¤æ‚åº¦
# è¿”å›çš„æ˜¯ä¸€ä¸ªå¯ç›´æ¥ç”¨äºæ„å»ºå®Œæ•´é…å‡†æ¨¡å‹çš„ Keras å­æ¨¡å—
# è¿™æ˜¯ VoxelMorph å®ç°å¿«é€Ÿã€æ— ç›‘ç£ã€ç«¯åˆ°ç«¯å›¾åƒé…å‡†çš„å…³é”®ç»„ä»¶ä¹‹ä¸€ã€‚

print('input shape: ', unet.input.shape)
print('output shape:', unet.output.shape)

# transform the results into a flow field.
disp_tensor = tf.keras.layers.Conv2D(ndim, kernel_size=3, padding='same', name='disp')(unet.output)
# åœ¨ U-Net çš„è¾“å‡ºï¼ˆå¦‚ (None, 32, 32, 16)ï¼‰ä¸Šåº”ç”¨ä¸€ä¸ª 1Ã—1 æˆ– 3Ã—3 å·ç§¯å±‚ï¼Œå°†å…¶é€šé“æ•°å‹ç¼©ä¸º ndimã€‚
# è¾“å‡ºå³ä¸º ä½ç§»åœºï¼ˆdisplacement fieldï¼‰ï¼Œè¡¨ç¤ºæ¯ä¸ªåƒç´ éœ€è¦ç§»åŠ¨çš„å‘é‡ã€‚

# è¾“å…¥ï¼šunet.outputï¼Œå‡è®¾å½¢çŠ¶ä¸º (None, 32, 32, 16)  Noneâ†’ è¡¨ç¤º batch å¤§å°ä¸å®šï¼Œå›¾åƒ 32Ã—32ï¼Œ16 ä¸ªç‰¹å¾é€šé“ã€‚
# æ“ä½œï¼šç”¨ä¸€ä¸ª 3Ã—3 å·ç§¯ å°† 16 é€šé“å‹ç¼©ä¸º ndim é€šé“ã€‚
# è¾“å‡ºï¼šdisp_tensorï¼Œå½¢çŠ¶ä¸º (None, 32, 32, ndim)
# è‹¥ ndim=2ï¼ˆ2D å›¾åƒï¼‰ï¼Œåˆ™è¾“å‡ºæ¯ä¸ªåƒç´ çš„ (dx, dy) ä½ç§»å‘é‡
# è‹¥ ndim=3ï¼ˆ3D å›¾åƒï¼‰ï¼Œåˆ™è¾“å‡º (dx, dy, dz)
# ğŸ’¡ è™½ç„¶æ³¨é‡Šè¯´â€œ1Ã—1 æˆ– 3Ã—3â€ï¼Œä½†è¿™é‡Œæ˜ç¡®ç”¨äº† kernel_size=3ã€‚
# å®é™…ä¸Šï¼Œ3Ã—3 å·ç§¯æ¯” 1Ã—1 æ›´å¥½ï¼šèƒ½åˆ©ç”¨å±€éƒ¨ä¸Šä¸‹æ–‡ä¿¡æ¯å¹³æ»‘ä½ç§»åœºï¼Œé¿å…å™ªå£°ã€‚

# check tensor shape
print('displacement tensor:', disp_tensor.shape)

# using keras, we can easily form new models via tensor pointers
def_model = tf.keras.models.Model(unet.inputs, disp_tensor)
# ğŸ“Œ å«ä¹‰ï¼šåˆ›å»ºä¸€ä¸ªæ–°çš„ Keras æ¨¡å‹ def_model
# è¾“å…¥ï¼šunet.inputsï¼ˆå³åŸå§‹æ‹¼æ¥å›¾åƒï¼Œå¦‚ (None, 32, 32, 2)ï¼‰
# è¾“å‡ºï¼šdisp_tensorï¼ˆå³ä½ç§»åœº (None, 32, 32, ndim)ï¼‰
# âœ… ä¸ºä»€ä¹ˆè¿™æ ·åšï¼Ÿ
# åŸå§‹ unet è¾“å‡ºçš„æ˜¯ä¸­é—´ç‰¹å¾ï¼ˆå¦‚ 16 é€šé“ï¼‰ï¼Œè€Œæˆ‘ä»¬çœŸæ­£éœ€è¦çš„æ˜¯ä½ç§»åœºã€‚
# é€šè¿‡ Model(inputs, outputs)ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥æ„å»ºä»è¾“å…¥å›¾åƒåˆ°ä½ç§»åœºçš„ç«¯åˆ°ç«¯æ˜ å°„ã€‚
# è¿™ä¸ª def_model å¯ä»¥ï¼š
# å•ç‹¬ç”¨äºæ¨ç†ï¼ˆé¢„æµ‹å½¢å˜åœºï¼‰
# ä½œä¸ºæ›´å¤§æ¨¡å‹ï¼ˆå¦‚å®Œæ•´é…å‡†æ¨¡å‹ï¼‰çš„ä¸€éƒ¨åˆ†
# ğŸ”— è¿™ä½“ç°äº† Keras çš„æ ¸å¿ƒä¼˜åŠ¿ï¼šé€šè¿‡å¼ é‡æŒ‡é’ˆï¼ˆtensor pointersï¼‰çµæ´»ç»„è£…æ¨¡å‹

# ç³»ç»Ÿè§£é‡Š
# tf.keras.models.Model(inputs, outputs, name=None)
# inputsï¼šæ¨¡å‹çš„è¾“å…¥å¼ é‡ï¼ˆæˆ–å¼ é‡åˆ—è¡¨ï¼‰ã€‚    # å¯ä»¥æ˜¯å•ä¸ª tf.Tensorï¼ˆå¦‚ unet.inputï¼‰ï¼Œä¹Ÿå¯ä»¥æ˜¯å¤šä¸ªå¼ é‡ç»„æˆçš„åˆ—è¡¨ï¼ˆå¦‚ [input1, input2]ï¼‰ã€‚
# åœ¨æœ¬ä¾‹ä¸­ï¼Œunet.inputs æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ˆå³ä½¿åªæœ‰ä¸€ä¸ªè¾“å…¥ï¼ŒKeras é€šå¸¸ä¹Ÿä»¥åˆ—è¡¨å½¢å¼å­˜å‚¨ï¼‰ã€‚
# outputsï¼šæ¨¡å‹çš„è¾“å‡ºå¼ é‡ï¼ˆæˆ–å¼ é‡åˆ—è¡¨ï¼‰ã€‚   # è¡¨ç¤ºä»è¾“å…¥ç»è¿‡ä¸€ç³»åˆ—å±‚è®¡ç®—åå¾—åˆ°çš„æœ€ç»ˆç»“æœã€‚
# æœ¬ä¾‹ä¸­ disp_tensor æ˜¯ä¸€ä¸ª tf.Tensorï¼Œç”± Conv2D å±‚ä½œç”¨äº unet.output å¾—åˆ°ã€‚
# nameï¼ˆå¯é€‰ï¼‰ï¼šä¸ºæ¨¡å‹æŒ‡å®šåç§°ï¼Œä¾¿äºè°ƒè¯•æˆ–å¯è§†åŒ–ã€‚
# âœ… è¯¥æ„é€ å‡½æ•°ä¼šè‡ªåŠ¨è¿½è¸ªä» inputs åˆ° outputs çš„æ‰€æœ‰è®¡ç®—è·¯å¾„ï¼Œæ„å»ºå®Œæ•´çš„è®¡ç®—å›¾ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªå¯è®­ç»ƒã€å¯ä¿å­˜ã€å¯è°ƒç”¨çš„ tf.keras.Model å®ä¾‹ã€‚

# æŸ¥çœ‹ç»“æ„
# def_model.summary()

# Loss
# #############################################################################################################################################################
# build transformer layer
print("---start to set loss---")
spatial_transformer = vxm.layers.SpatialTransformer(name='transformer')
# âœ… åŠŸèƒ½ï¼š# åˆ›å»ºä¸€ä¸ª å¯å¾®åˆ†çš„ç©ºé—´å˜æ¢æ¨¡å—ï¼Œèƒ½æ ¹æ®ä½ç§»åœºå¯¹å›¾åƒè¿›è¡Œå½¢å˜ã€‚
# è¿™æ˜¯ VoxelMorph è‡ªå®šä¹‰çš„ Keras å±‚ï¼Œå°è£…äº† ç½‘æ ¼é‡‡æ ·ï¼ˆgrid samplingï¼‰ æˆ– åŒçº¿æ€§æ’å€¼ï¼ˆbilinear interpolationï¼‰ çš„å®ç°ã€‚
# å…³é”®ç‰¹æ€§ï¼š # å¯å¾®åˆ†ï¼ˆdifferentiableï¼‰ï¼šæ¢¯åº¦å¯ä»¥åå‘ä¼ æ’­åˆ°ä½ç§»åœºï¼Œä»è€Œç«¯åˆ°ç«¯è®­ç»ƒæ•´ä¸ªç½‘ç»œã€‚# æ”¯æŒ 2D/3Dï¼šè‡ªåŠ¨æ ¹æ®è¾“å…¥å¼ é‡ç»´åº¦é€‰æ‹©å®ç°ã€‚
# è¾“å…¥è¦æ±‚ï¼š # [source_image, displacement_field]     # source_image: (B, H, W, 1)ï¼ˆ2Dï¼‰æˆ– (B, D, H, W, 1)ï¼ˆ3Dï¼‰
# displacement_field: (B, H, W, 2) æˆ– (B, D, H, W, 3)
# ğŸ’¡ è¿™ä¸ªå±‚æ˜¯ VoxelMorph èƒ½å®ç° æ— ç›‘ç£é…å‡† çš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€â€”â€”æ— éœ€ ground truth å½¢å˜ï¼Œä»…é å›¾åƒç›¸ä¼¼æ€§å³å¯è®­ç»ƒã€‚

# extract the first frame (i.e. the "moving" image) from unet input tensor
moving_image = tf.expand_dims(unet.input[..., 0], axis=-1)
# åˆ†æ­¥è§£æï¼š
# 1. unet.input
# è¿™æ˜¯ Keras æ¨¡å‹çš„è¾“å…¥å¼ é‡ï¼ˆtf.Tensor æˆ– KerasTensorï¼‰ã€‚
# å½¢çŠ¶å¦‚ (B, H, W, D, 2)

# 2. unet.input[..., 0]
# ... è¡¨ç¤ºâ€œæ‰€æœ‰å‰é¢çš„ç»´åº¦â€
# [..., 0] ç›¸å½“äºå–æœ€åä¸€ç»´ï¼ˆé€šé“ç»´ï¼‰çš„ç¬¬ 0 ä¸ªé€šé“ï¼Œ å¤‡æ³¨ï¼šunet.input æ˜¯ä¸¤å¼ å›¾(0:fixed, 1:moving)çš„æ‹¼è£…ã€‚
# ç»“æœå½¢çŠ¶ï¼š(B, H, W, D) â† å°‘äº†é€šé“ç»´
# âš ï¸ é—®é¢˜ï¼šå¤§å¤šæ•°å›¾åƒå¤„ç†å±‚ï¼ˆåŒ…æ‹¬ SpatialTransformerï¼‰æœŸæœ›è¾“å…¥æœ‰æ˜¾å¼çš„é€šé“ç»´ï¼ˆå³ä½¿åªæœ‰ 1 ä¸ªé€šé“ï¼‰ã€‚
#
# 3. tf.expand_dims(..., axis=-1)
# åœ¨æœ€åä¸€ä¸ªç»´åº¦ï¼ˆå³é€šé“ç»´ï¼‰ä¸Šå¢åŠ ä¸€ä¸ªå¤§å°ä¸º 1 çš„æ–°ç»´åº¦
# è¾“å…¥å½¢çŠ¶ (B, H, W, D) â†’ è¾“å‡ºå½¢çŠ¶ (B, H, W, D, 1)
# âœ… ç›®çš„ï¼šæ¢å¤æ ‡å‡†çš„å›¾åƒå¼ é‡æ ¼å¼ï¼Œç¬¦åˆåç»­å±‚çš„è¾“å…¥è¦æ±‚ã€‚

# warp the moving image with the transformer
moved_image_tensor = spatial_transformer([moving_image, disp_tensor])
# æ˜¯åœ¨æ¨¡å‹æ„å»ºé˜¶æ®µï¼Œå°† SpatialTransformer å±‚â€œè¿æ¥â€åˆ°è®¡ç®—å›¾ä¸­ï¼Œç”Ÿæˆä¸€ä¸ªä»£è¡¨å½¢å˜ç»“æœçš„è¾“å‡ºå¼ é‡ã€‚
print("moved_image_tensor shape", moved_image_tensor.shape) # æ³¨æ„ï¼šè¾“å‡ºä¸ºä¸€ä¸ª2Dçš„å›¾åƒï¼Œæ˜¯ç”±moving imageå˜æ¢å¾—åˆ°çš„Moved image

outputs = [moved_image_tensor, disp_tensor]
# è¿™é‡Œä½¿ç”¨äº† Python çš„åˆ—è¡¨å­—é¢é‡è¡¨ç¤ºæ³•æ¥åˆ›å»ºä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå…ƒç´ çš„åˆ—è¡¨
# å®šä¹‰æ¨¡å‹çš„ä¸¤ä¸ªè¾“å‡ºï¼šé…å‡†ç»“æœ + å½¢å˜åœº

vxm_model = tf.keras.models.Model(inputs=unet.inputs, outputs=outputs)  ## ç»§ç»­çœ‹ 12-28
# âœ… ç»“æœï¼š # vxm_model æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯å¯è®­ç»ƒçš„æ¨¡å‹ã€‚
# è°ƒç”¨ vxm_model([fixed, moving]) ä¼šåŒæ—¶è¿”å›ï¼š
# warped_img, displacement = vxm_model([fixed_batch, moving_batch])
# ä¹‹å‰ç¬¬ä¸€æ¬¡tf.keras.models.Modelæ‹¼æ¥å®ç°äº†ä»unet.inputsï¼ˆfixed, movingï¼‰ å¾—åˆ°ä¸€ä¸ªå˜å½¢åœºdisp_tensor
# ç¬¬äºŒæ¬¡æ‹¼æ¥ï¼Œå®ç°äº†ä»unet.inputs è®¡ç®— å¾—åˆ° outputs = [moved_image_tensor, disp_tensor]ï¼Œå³ä¸€ä¸ªå˜å½¢åçš„å›¾åƒï¼Œé™„å¸¦ä¹‹å‰çš„å˜å½¢åœºã€‚

from tensorflow.keras.utils import plot_model

plot_model(
    vxm_model,
    to_file='vxm_model.png',
    show_shapes=True,      # æ˜¾ç¤ºå¼ é‡å½¢çŠ¶
    show_dtype=False,
    show_layer_names=True,
    rankdir='TB',          # 'TB' = top to bottom, 'LR' = left to right
    expand_nested=False,
    dpi=96
)

# build model using VxmDense
inshape = x_train.shape[1:]
print("x_train.shape[1:]", inshape)

vxm_model = vxm.networks.VxmDense(inshape, nb_features, int_steps=0)
# è¿™æ˜¯è°ƒç”¨ VoxelMorphåº“ä¸­çš„ VxmDense ç±»æ¥æ„å»ºä¸€ä¸ªå®Œæ•´çš„ç«¯åˆ°ç«¯é…å‡†ç½‘ç»œã€‚
# ğŸ”¸ ä»€ä¹ˆæ˜¯ VxmDenseï¼Ÿ
# å®ƒæ˜¯ VoxelMorph æä¾›çš„ä¸€ä¸ªé¢„å®šä¹‰æ¨¡å‹ç±»ï¼Œå°è£…äº†ï¼š# ä¸€ä¸ª U-Net ç¼–ç å™¨-è§£ç å™¨# ä¸€ä¸ª å¯é€‰çš„å¾®åˆ†åŒèƒšç§¯åˆ†æ¨¡å—ï¼ˆVecIntï¼‰# ä¸€ä¸ª SpatialTransformerå±‚
# è¾“å…¥ï¼šä¸€å¯¹å›¾åƒ [fixed, moving] # è¾“å‡ºï¼š[warped_moving, displacement_field]
# ğŸ”¹ å‚æ•°è¯¦è§£
# âœ… 1. in-shape
# ç±»å‹ï¼štupleï¼Œå¦‚ (160, 192, 224, 1)ï¼ˆ3Dï¼‰æˆ– (256, 256, 1)ï¼ˆ2Dï¼‰
# å«ä¹‰ï¼šå•ä¸ªè¾“å…¥å›¾åƒçš„å½¢çŠ¶ï¼ˆä¸å« batch ç»´ï¼‰
# ç”¨é€”ï¼šç”¨äºåˆå§‹åŒ– U-Net çš„è¾“å…¥å±‚å’Œ SpatialTransformer# ğŸ’¡ å¦‚å›¾åƒæ˜¯ (128, 128, 128) ä¸”å•é€šé“ï¼Œinshape = (128, 128, 128, 1)
# âœ… 2. nb_features
# ç±»å‹ï¼šlist of listsï¼Œå®šä¹‰ U-Net æ¯ä¸€å±‚çš„ç‰¹å¾å›¾æ•°é‡# å…¸å‹å€¼ï¼š# nb_features = [[16, 32, 32, 32],  #encoder: æ¯å±‚å·ç§¯çš„æ»¤æ³¢å™¨æ•°
#     [32, 32, 32, 32, 32, 16, 16]  ] # decoder
# ç»“æ„ï¼š[encoder_filters, decoder_filters]  # ä½œç”¨ï¼šæ§åˆ¶æ¨¡å‹å®¹é‡å’Œæ„Ÿå—é‡
# âœ… 3. int_steps=0
# å«ä¹‰ï¼šå¾®åˆ†åŒèƒšç§¯åˆ†ï¼ˆdiffeomorphic integrationï¼‰å…³é”®æœºåˆ¶ï¼š
# è‹¥ int_steps > 0ï¼šU-Net é¢„æµ‹çš„æ˜¯é€Ÿåº¦åœºï¼ˆvelocity fieldï¼‰ï¼Œç„¶åé€šè¿‡ scaling and squaring ç§¯åˆ†å¾—åˆ°å½¢å˜åœº Ï† = exp(v)
# è‹¥ int_steps = 0ï¼šU-Net ç›´æ¥é¢„æµ‹ä½ç§»åœºï¼ˆdisplacement fieldï¼‰uï¼Œå³ Ï†(x) = x + u(x)

print('input shape: ', ', '.join([str(t.shape) for t in vxm_model.inputs]))
print('output shape:', ', '.join([str(t.shape) for t in vxm_model.outputs]))

# voxelmorph has a variety of custom loss classes
losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]
# 1. vxm.losses.MSE().loss
# å…¨ç§°ï¼šMean Squared Errorï¼ˆå‡æ–¹è¯¯å·®ï¼‰
# 2. vxm.losses.Grad('l2').loss
# å…¨ç§°ï¼šDisplacement Field Gradient Regularizationï¼ˆä½ç§»åœºæ¢¯åº¦æ­£åˆ™åŒ–ï¼‰
# æ ¸å¿ƒæ€æƒ³ï¼šæƒ©ç½šä½ç§»åœºçš„ç©ºé—´å‰§çƒˆå˜åŒ–ï¼ˆå³é¼“åŠ±å¹³æ»‘ï¼‰

# usually, we have to balance the two losses by a hyper-parameter
lambda_param = 0.05
loss_weights = [1, lambda_param]
# ç›¸ä¼¼æ€§æŸå¤±ï¼ˆå¦‚ MSEï¼‰çš„å€¼å¯èƒ½åœ¨ [0, 1] èŒƒå›´
# æ­£åˆ™åŒ–æŸå¤±ï¼ˆæ¢¯åº¦å¹³æ–¹å’Œï¼‰å¯èƒ½éå¸¸å¤§ï¼ˆå¦‚ 1000ï¼‰
# å¦‚æœç›´æ¥ç›¸åŠ ï¼Œæ­£åˆ™é¡¹ä¼šä¸»å¯¼ä¼˜åŒ–ï¼Œ # å› æ­¤å¼•å…¥è¶…å‚æ•° Î» æ§åˆ¶æ­£åˆ™å¼ºåº¦ï¼š

vxm_model.compile(optimizer='Adam', loss=losses, loss_weights=loss_weights)  ## 12-29 ç»§ç»­
# æ€»ç»“
# ç»´åº¦	        è¯´æ˜
# è¯­æ³•æœ¬è´¨	    Keras æ¨¡å‹è®­ç»ƒå‰çš„é…ç½®æ­¥éª¤
# æ ¸å¿ƒåŠŸèƒ½	    å®šä¹‰ä¼˜åŒ–å™¨ã€å¤šä»»åŠ¡æŸå¤±åŠå…¶æƒé‡
# åœ¨é…å‡†ä¸­çš„ä½œç”¨	å®ç° ç›¸ä¼¼æ€§ + æ­£åˆ™åŒ– çš„æ— ç›‘ç£å­¦ä¹ ç›®æ ‡
# å…³é”®çº¦å®š	    losses[i] å¯¹åº” model.outputs[i]
# å…¸å‹å€¼	        losses = [MSE, Grad], loss_weights = [1.0, 0.01]
# ğŸ’¡ ä¸€å¥è¯æ¦‚æ‹¬ï¼šcompile() å°†ä½ çš„ç‰©ç†å…ˆéªŒï¼ˆå¹³æ»‘å½¢å˜ï¼‰ å’Œä»»åŠ¡ç›®æ ‡ï¼ˆå›¾åƒå¯¹é½ï¼‰ è½¬åŒ–ä¸ºå¯ä¼˜åŒ–çš„æ•°å­¦è¡¨è¾¾å¼ï¼Œæ˜¯è¿æ¥æ¨¡å‹ç»“æ„ä¸è®­ç»ƒç›®æ ‡çš„æ¡¥æ¢ã€‚

# Train Model
# #############################################################################################################################################################
print("---start to train model---")
def vxm_data_generator(x_data, batch_size=32):
    """
    Generator that takes in data of size [N, H, W], and yields data for
    our custom vxm model. Note that we need to provide numpy data for each
    input, and each output.
    è¯¥ç”Ÿæˆå™¨æ¥æ”¶å¤§å°ä¸º [N, H, W] çš„æ•°æ®ï¼Œå¹¶ç”Ÿæˆç”¨äºæˆ‘ä»¬è‡ªå®šä¹‰ vxm æ¨¡å‹çš„æ•°æ®ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ¯ä¸ªè¾“å…¥å’Œæ¯ä¸ªè¾“å‡ºæä¾› numpy æ•°æ®ã€‚

    inputs:  moving [bs, H, W, 1], fixed image [bs, H, W, 1]
    outputs: moved image [bs, H, W, 1], zero-gradient [bs, H, W, 2]
    """

    # preliminary sizing
    vol_shape = x_data.shape[1:]  # extract data shape
    ndims = len(vol_shape)
    # æå–å›¾åƒå½¢çŠ¶å’Œç»´åº¦:    # vol_shapeï¼šå•ä¸ªå›¾åƒçš„ç©ºé—´å°ºå¯¸    # ndimsï¼šåˆ¤æ–­æ˜¯ 2D è¿˜æ˜¯3Dæ•°æ®ï¼ˆå†³å®šä½ç§»åœºé€šé“æ•°ï¼‰

    # prepare a zero array the size of the deformation
    # we'll explain this below
    zero_phi = np.zeros([batch_size, *vol_shape, ndims])
    # 2.    åˆ›å»ºé›¶ä½ç§»åœºæ¨¡æ¿
    # å½¢çŠ¶ç¤ºä¾‹ï¼ˆ3Dï¼‰ï¼š(32, 128, 128, 128, 3)
    # ç”¨é€”ï¼šä½œä¸ºæ¨¡å‹ç¬¬äºŒä¸ªè¾“å‡ºï¼ˆä½ç§»åœºï¼‰çš„â€œå‡æ ‡ç­¾â€
    # ä¸ºä»€ä¹ˆéœ€è¦ï¼Ÿ
    # Kerasè¦æ±‚å¤šè¾“å‡ºæ¨¡å‹çš„outputså¿…é¡»ä¸lossåˆ—è¡¨é•¿åº¦ä¸€è‡´
    # è™½ç„¶GradæŸå¤±ä¸ä½¿ç”¨y_trueï¼Œä½†ä»éœ€æä¾›ä¸€ä¸ªåŒå½¢çŠ¶çš„å¼ é‡å ä½
    # ğŸ’¡ è¿™æ˜¯ä¸€ä¸ªæ¥å£å…¼å®¹æ€§è®¾è®¡ï¼Œå®é™…è®­ç»ƒä¸­zero_phiçš„å€¼æ— å…³ç´§è¦ã€‚

    while True:
        # ä½¿ç”Ÿæˆå™¨å¯è¢«model.fit(steps_per_epoch=...)æ— é™è°ƒç”¨
        # é¿å…epochç»“æŸæ—¶åœæ­¢ï¼ˆé€‚åˆæ— ç›‘ç£è‡ªç›‘ç£ä»»åŠ¡ï¼‰
        # prepare inputs:
        # images need to be of the size [batch_size, H, W, 1]
        idx1 = np.random.randint(0, x_data.shape[0], size=batch_size)
        # x_data.shape[0] è¡¨ç¤ºæ•°æ®é›†ä¸­çš„æ ·æœ¬æ€»æ•°ï¼ˆå³ batch ç»´åº¦å¤§å°ï¼‰
        # np.random.randint(0, N, size=k) ç”Ÿæˆä¸€ä¸ªé•¿åº¦ä¸º k çš„ä¸€ç»´ NumPy æ•°ç»„ æ¯ä¸ªå…ƒç´ æ˜¯ [0, N) èŒƒå›´å†…çš„éšæœºæ•´æ•° å…è®¸é‡å¤ï¼ˆå³æœ‰æ”¾å›æŠ½æ ·ï¼‰
        # è‹¥éœ€â€œæ— æ”¾å›â€ï¼Œå¯ç”¨ np.random.choice(..., replace=False)ï¼Œä½†è¦æ±‚ batch_size â‰¤ N

        moving_images = x_data[idx1, ..., np.newaxis]
        # è¿™è¡Œä»£ç çš„ä½œç”¨æ˜¯ä»x_dataä¸­æ ¹æ®ç´¢å¼•idx1æå–å‡ºä¸€æ‰¹æ ·æœ¬ï¼Œå¹¶é€šè¿‡np.newaxiså¢åŠ ä¸€ä¸ªæ–°çš„ç»´åº¦ã€‚
        # å…·ä½“æ¥è¯´ï¼Œå¦‚æœåŸå§‹x_dataçš„å½¢çŠ¶æ˜¯(N, H, W)ï¼Œé‚£ä¹ˆæå–å‡ºçš„moving_imageså½¢çŠ¶å°†ä¼šæ˜¯(batch_size, H, W, 1)ã€‚è¿™ä¸ªæ–°æ·»åŠ çš„ç»´åº¦é€šå¸¸ç”¨äºè¡¨ç¤ºé€šé“æ•°ï¼Œåœ¨å›¾åƒå¤„ç†ä¸­ç‰¹åˆ«æœ‰ç”¨ã€‚

        idx2 = np.random.randint(0, x_data.shape[0], size=batch_size)
        fixed_images = x_data[idx2, ..., np.newaxis]

        inputs = [moving_images, fixed_images]

        # prepare outputs (the 'true' moved image):
        # of course, we don't have this, but we know we want to compare
        # the resulting moved image with the fixed image.
        # we also wish to penalize the deformation field.
        outputs = [fixed_images, zero_phi]

        yield (inputs, outputs)


# let's test it
train_generator = vxm_data_generator(x_train)
# vxm_data_generatoræ˜¯ä»€ä¹ˆï¼Ÿï¼š
# ä½ ä¹‹å‰å®šä¹‰çš„ç”Ÿæˆå™¨å‡½æ•°ï¼ˆgenerator functionï¼‰
# x_trainï¼šè®­ç»ƒæ•°æ®ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ª NumPy æ•°ç»„ï¼Œå½¢çŠ¶å¦‚ (N, H, W) æˆ– (N, H, W, D)ï¼Œè¡¨ç¤º N ä¸ªåŒ»å­¦å›¾åƒ
# è°ƒç”¨æ—¶æœªæŒ‡å®š batch_sizeï¼Œä½¿ç”¨é»˜è®¤å€¼ 32

# train_generator æ˜¯ä»€ä¹ˆï¼Ÿ
# å®ƒæ˜¯ä¸€ä¸ª æƒ°æ€§è¿­ä»£å™¨ï¼ˆlazy iteratorï¼‰
# å†…éƒ¨ä¿å­˜äº†ï¼š# å¯¹ x_train çš„å¼•ç”¨ï¼›# é»˜è®¤ batch_size=32ï¼›# å‡½æ•°æ‰§è¡Œçš„â€œæŒ‚èµ·ç‚¹â€ï¼ˆåˆå§‹ä¸ºå‡½æ•°å¼€å¤´ï¼‰
# å¦‚ä½•è·å–æ•°æ®ï¼Ÿ é€šè¿‡è¿­ä»£æˆ– next()ï¼š

in_sample, out_sample = next(train_generator)
# next(train_generator)	ä»ç”Ÿæˆå™¨è·å–ä¸‹ä¸€ä¸ª (inputs, outputs) å…ƒç»„
# in_sample, out_sample = ...	è§£åŒ…ä¸ºè¾“å…¥å’Œè¾“å‡ºä¸¤éƒ¨åˆ†ï¼Œä¾¿äºå•ç‹¬æ“ä½œ
# ç›®çš„	è°ƒè¯•ã€å¯è§†åŒ–ã€è‡ªå®šä¹‰è®­ç»ƒç­‰éœ€è¦æ˜¾å¼è®¿é—®å•ä¸ª batch çš„åœºæ™¯
# å‰æ	ç”Ÿæˆå™¨å¿…é¡»æŒ‰ Keras çº¦å®š yield (inputs, outputs)

# visualize
comb = in_sample + out_sample

images = [img[0, :, :, 0] for img in comb]
# imagesæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œç”¨äºä»combä¸­å­˜å‚¨çš„4ä¸ªå‘é‡ä¸­çš„æ¯ä¸€ä¸ªä¸­æå–ä¸€ä¸ªå…ƒç´ ï¼šimg[0, :, :, 0]ï¼Œè¿™åˆæ˜¯ä¸€ä¸ªåŸºæœ¬ç´¢å¼•æ“ä½œï¼ˆæ•´æ•°+åˆ‡ç‰‡ï¼‰ï¼Œç»“æœæ˜¯ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç¬¬ä¸€ä¸ªé€šé“åˆ‡ç‰‡ã€‚

titles = ['moving', 'fixed', 'moved ground-truth (fixed)', 'zeros']
ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True)
# è°ƒç”¨ ne.plot.slices æ¥ç»˜åˆ¶å›¾åƒåˆ‡ç‰‡ï¼š
# imagesï¼šä¸€ä¸ªåŒ…å«å››å¼  2D æˆ– 3D å›¾åƒçš„åˆ—è¡¨æˆ–æ•°ç»„ï¼ˆå¦‚ [img1, img2, img3, img4]ï¼‰ï¼Œé¡ºåºå¿…é¡»ä¸ titles å¯¹åº”ã€‚
# titles=titlesï¼šä¸ºæ¯å¼ å›¾åƒè®¾ç½®å¯¹åº”çš„æ ‡é¢˜ã€‚
# cmaps=['gray']ï¼šæŒ‡å®šæ‰€æœ‰å›¾åƒä½¿ç”¨ç°åº¦ colormapï¼ˆåŒ»å­¦å›¾åƒå¸¸ç”¨ï¼‰ã€‚æ³¨æ„è¿™é‡Œè™½ç„¶æ˜¯åˆ—è¡¨å½¢å¼ï¼Œä½†åªä¼ äº†ä¸€ä¸ª 'gray'ï¼Œå‡½æ•°å†…éƒ¨ä¼šè‡ªåŠ¨å¹¿æ’­åˆ°æ‰€æœ‰å­å›¾ã€‚
# do_colorbars=Trueï¼šåœ¨æ¯å¼ å­å›¾æ—è¾¹æ˜¾ç¤ºé¢œè‰²æ¡ï¼ˆcolorbarï¼‰ï¼Œç”¨äºæŒ‡ç¤ºåƒç´ å€¼èŒƒå›´ã€‚

nb_epochs = 3
steps_per_epoch = 100
hist = vxm_model.fit_generator(train_generator, epochs=nb_epochs, steps_per_epoch=steps_per_epoch, verbose=2)
# è¿™æ˜¯ Kerasï¼ˆæˆ– TensorFlow < 2.1ï¼‰ä¸­ç”¨äºè®­ç»ƒæ¨¡å‹çš„å‡½æ•°ï¼ˆåœ¨ TF â‰¥ 2.1 åæ¨èä½¿ç”¨ model.fit()ï¼Œä½† fit_generator åœ¨æ—§ç‰ˆ VoxelMorph ä¸­ä»å¸¸è§ï¼‰ã€‚
# # å‚æ•°è¯¦è§£ï¼š
# 1-train_generatorï¼šä¸€ä¸ª Python ç”Ÿæˆå™¨ï¼ˆgeneratorï¼‰ï¼Œæ¯æ¬¡è°ƒç”¨ next() ä¼šè¿”å›ä¸€ä¸ª batch çš„è®­ç»ƒæ•°æ®ã€‚
# å¯¹äº VoxelMorphï¼Œé€šå¸¸è¿”å›æ ¼å¼ä¸ºï¼š ([moving_batch, fixed_batch], [fixed_batch, zero_disp_field])
# å…¶ä¸­ï¼š     è¾“å…¥æ˜¯ (moving, fixed) å›¾åƒå¯¹ï¼›#è¾“å‡ºåŒ…æ‹¬é‡å»ºå›¾åƒï¼ˆåº”æ¥è¿‘ fixedï¼‰å’Œå½¢å˜åœºï¼ˆç›‘ç£ä¿¡å·å¯èƒ½ä¸ºé›¶ï¼Œè‹¥ä½¿ç”¨æ— ç›‘ç£é…å‡†ï¼‰ã€‚
# 2-epochs=nb_epochsï¼š# è®­ç»ƒ 10 ä¸ª epochã€‚
# 3-steps_per_epoch=steps_per_epochï¼š# æ¯ä¸ª epoch è·‘ 100 æ­¥ã€‚
# 4-verbose=2ï¼š# æ§åˆ¶è®­ç»ƒæ—¥å¿—è¾“å‡ºçš„è¯¦ç»†ç¨‹åº¦ï¼š# 0ï¼šé™é»˜ï¼›# 1ï¼šè¿›åº¦æ¡ï¼ˆå®æ—¶æ›´æ–°ï¼‰ï¼›# 2ï¼šæ¯ä¸ª epoch ç»“æŸåæ‰“å°ä¸€è¡Œæ‘˜è¦ï¼ˆå¦‚ loss å€¼ï¼‰ï¼Œé€‚åˆæ—¥å¿—è®°å½•ã€‚
# 5-histï¼š# è¿”å›ä¸€ä¸ª History å¯¹è±¡ï¼ŒåŒ…å«è®­ç»ƒè¿‡ç¨‹ä¸­æ¯ä¸ª epoch çš„ loss å’Œ metricsï¼ˆå¦‚ loss, dec_loss, grad_loss ç­‰ï¼‰ï¼Œå¯ç”¨äºåç»­ç»˜å›¾æˆ–åˆ†æã€‚

import matplotlib.pyplot as plt


def plot_history(hist, loss_name='loss'):
    # Simple function to plot training history.
    plt.figure()
    plt.plot(hist.epoch, hist.history[loss_name], '.-')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.show()

plot_history(hist)

# Registration
# #############################################################################################################################################################
# let's get some data
print("---start Registration---")
val_generator = vxm_data_generator(x_val, batch_size=1)
# ä½œç”¨ï¼šåˆ›å»ºä¸€ä¸ªæ¯æ¬¡è¿”å› 1 å¯¹éªŒè¯å›¾åƒçš„ç”Ÿæˆå™¨

val_input, _ = next(val_generator)
# ä½œç”¨ï¼šä»ç”Ÿæˆå™¨ä¸­å–å‡ºä¸€ä¸ª batch çš„æ•°æ®ï¼Œåªä¿ç•™è¾“å…¥éƒ¨åˆ†ï¼ˆinputsï¼‰ï¼Œå¿½ç•¥ç›®æ ‡ï¼ˆtargetsï¼‰

import time

start = time.time()

val_pred = vxm_model.predict(val_input)
# å°† val_input è¾“å…¥åˆ°å·²è®­ç»ƒçš„ VoxelMorph ç½‘ç»œä¸­ï¼Œç½‘ç»œå‰å‘ä¼ æ’­ï¼Œç”Ÿæˆä¸¤ä¸ªè¾“å‡ºï¼š
# é…å‡†åçš„å›¾åƒï¼ˆwarped moving imageï¼‰ å½¢å˜åœºï¼ˆdeformation field / flowï¼‰# è¿”å›ç»“æœå¹¶èµ‹å€¼ç»™ val_pred

# %timeit is a 'jupyter magic' that times the given line over several runs
# %timeit vxm_model.predict(val_input)

elapsed = time.time() - start
print(f"Inference time: {elapsed:.2f} s")

print("Type of val_input:", type(val_input), "Shape of val_input:", val_input[0].shape)
print("Type of val_pred:", type(val_pred), "Shape of val_pred:", val_pred[0].shape)

# visualize
images = [img[0, :, :, 0] for img in val_input + list(val_pred)]
# inputs = [moving_images, fixed_images]ï¼Œ    outputs = [wrapped_images, flow]

titles = ['moving', 'fixed', 'moved', 'flow']  # è®¾ç½®å›¾åƒæ ‡é¢˜
ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True)
# ne æ˜¯ neurite åº“ï¼ˆVoxelMorph å®˜æ–¹é…å¥—å¯è§†åŒ–å·¥å…·ï¼‰
# ne.plot.slices()ï¼šå°†å¤šä¸ª 2D å›¾åƒå¹¶æ’æ˜¾ç¤º
# å‚æ•°è¯´æ˜ï¼š
# cmaps=['gray']ï¼šæ‰€æœ‰å›¾åƒç”¨ç°åº¦ colormapï¼ˆé€‚åˆ MRI/USï¼‰
# do_colorbars=Trueï¼šæ˜¾ç¤ºé¢œè‰²æ¡ï¼ˆä¾¿äºè§‚å¯Ÿ intensity èŒƒå›´ï¼‰
# âœ… è¾“å‡ºæ•ˆæœï¼šä¸€è¡Œ 4 å¼ å›¾ï¼Œæ ‡æ³¨æ¸…æ™°ï¼Œå¸¦è‰²æ ‡ã€‚

# ç›´æ¥æ‰“å°å½¢çŠ¶
print(val_pred[1].shape)
ne.plot.flow([val_pred[1].squeeze()], width=5)

# Generalization æ³›åŒ–
# #############################################################################################################################################################
# extract only instances of the digit 7
print("---start Generalization---")
x_sevens = x_train_load[y_train_load == 7, ...].astype('float') / 255
# y_train_load == 7ï¼šå¸ƒå°”ç´¢å¼•ï¼Œè¿”å›ä¸€ä¸ªä¸æ ‡ç­¾é•¿åº¦ç›¸åŒçš„å¸ƒå°”æ•°ç»„ï¼Œå€¼ä¸º True çš„ä½ç½®å¯¹åº”æ ‡ç­¾ä¸º 7 çš„æ ·æœ¬ã€‚
# x_train_load[...]ï¼šç”¨è¯¥å¸ƒå°”æ•°ç»„ç´¢å¼• x_train_loadï¼Œé€‰å‡ºæ‰€æœ‰æ ‡ç­¾ä¸º 7 çš„å›¾åƒã€‚
# å‡è®¾ x_train_load shape æ˜¯ (N, H, W) æˆ– (N, H, W, 1)ï¼ˆMNIST é€šå¸¸æ˜¯ (60000, 28, 28)ï¼‰
# ç»“æœ x_sevens shape å¯èƒ½æ˜¯ (M, 28, 28)ï¼Œå…¶ä¸­ M æ˜¯æ•°å­— 7 çš„æ ·æœ¬æ•°ï¼ˆçº¦ 6000+ï¼‰
# .astype('float')ï¼šå°†æ•´å‹åƒç´ å€¼ï¼ˆ0â€“255ï¼‰è½¬ä¸ºæµ®ç‚¹å‹ï¼Œä¾¿äºåç»­é™¤æ³•ã€‚
# / 255ï¼šå½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´ï¼Œè¿™æ˜¯æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ ‡å‡†è¾“å…¥è¦æ±‚ã€‚

x_sevens = np.pad(x_sevens, pad_amount, 'constant')
# pad_amount = ((0, 0), (2, 2), (2, 2))
# è¯¥ä»£ç ä½¿ç”¨ NumPy çš„ pad å‡½æ•°ï¼Œåœ¨æ•°ç»„ x_sevens çš„è¾¹ç¼˜å¡«å……é›¶å€¼ï¼ˆzero-paddingï¼‰ï¼Œ
# ç›®çš„æ˜¯å°†å›¾åƒå°ºå¯¸ä» (N, 28, 28) æ‰©å±•ä¸º (N, 32, 32)ï¼Œä»¥æ»¡è¶³æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚ VoxelMorphã€U-Netï¼‰å¯¹è¾“å…¥å°ºå¯¸ä¸º 2 çš„å¹‚æ¬¡çš„è¦æ±‚ã€‚

# predict
seven_generator = vxm_data_generator(x_sevens, batch_size=1)
# åˆ›å»ºä¸€ä¸ªæ•°æ®ç”Ÿæˆå™¨ï¼ˆgeneratorï¼‰ï¼Œç”¨äºä»æ•°å­—â€œ7â€çš„å›¾åƒé›†åˆ x_sevens ä¸­åŠ¨æ€åœ°ã€æˆå¯¹åœ°é‡‡æ ·å›¾åƒï¼Œä»¥ä¾› VoxelMorph ç­‰æ— ç›‘ç£å›¾åƒé…å‡†æ¨¡å‹è®­ç»ƒæˆ–æ¨ç†ä½¿ç”¨ã€‚æ³¨æ„å·²æŒ‡å®šatch_size=1


seven_sample, _ = next(seven_generator)
# ä½œç”¨æ˜¯ä»ä¸€ä¸ªæ•°æ®ç”Ÿæˆå™¨ï¼ˆgeneratorï¼‰ seven_generator ä¸­è·å–ä¸‹ä¸€ä¸ª batch çš„æ•°æ®ï¼Œå¹¶å°†å…¶è§£åŒ…ä¸ºè¾“å…¥å’Œè¾“å‡ºä¸¤éƒ¨åˆ†ï¼Œå…¶ä¸­åªä¿ç•™è¾“å…¥éƒ¨åˆ† seven_sampleï¼Œè€Œå¿½ç•¥è¾“å‡ºéƒ¨åˆ†ï¼ˆç”¨ _ è¡¨ç¤ºä¸¢å¼ƒï¼‰ã€‚

seven_pred = vxm_model.predict(seven_sample)
# ä½¿ç”¨å·²è®­ç»ƒå¥½çš„ VoxelMorph æ¨¡å‹å¯¹ä¸€å¯¹å›¾åƒï¼ˆmoving å’Œ fixedï¼‰è¿›è¡Œæ¨ç†ï¼ˆinferenceï¼‰ï¼Œä»¥è·å¾—é…å‡†ç»“æœï¼ˆå³å½¢å˜åçš„å›¾åƒå’Œå½¢å˜åœºï¼‰


# visualize
images = [img[0, :, :, 0] for img in seven_sample + list(seven_pred)]
titles = ['moving', 'fixed', 'moved', 'flow']
ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True)
# cmaps=['gray']ï¼šæ‰€æœ‰å›¾åƒç”¨ç°åº¦ colormapï¼ˆé€‚åˆ MRI/USï¼‰
# do_colorbars=Trueï¼šæ˜¾ç¤ºé¢œè‰²æ¡ï¼ˆä¾¿äºè§‚å¯Ÿ intensity èŒƒå›´ï¼‰


# æˆ‘ä»¬æ¥è¯•è¯•å¦ä¸€ç§å˜åŒ–ã€‚å¦‚æœæˆ‘ä»¬åªä¿®æ”¹ï¼ˆåŸå§‹ï¼‰æ•°æ®é›†ï¼Œä½†å°†åƒç´ å¼ºåº¦ä¹˜ä»¥ä¸€ä¸ªç³»æ•°ï¼Œç»“æœä¼šæ€æ ·ï¼Ÿ
factor = 5

print("shape of val_input = ", val_input[0].shape)
# val_inputæ¥æºï¼š val_generator = vxm_data_generator(x_val, batch_size=1)  val_input, _ = next(val_generator)
moving_image = val_input[0]
fixed_image = val_input[1]

print('moving image pixel range: ', moving_image.min(), moving_image.max())
print('fixed image pixel range: ', fixed_image.min(), fixed_image.max())


# å¯¹è¾“å…¥å›¾åƒè¿›è¡Œæ”¾å¤§
scaled_moving_image = moving_image * factor
scaled_fixed_image = fixed_image * factor

print('scaled_moving image pixel range: ', scaled_moving_image.min(), scaled_moving_image.max())
print('scaled_fixed image pixel range: ', scaled_fixed_image.min(), scaled_fixed_image.max())

val_pred = vxm_model.predict([f * factor for f in val_input])
# val_input ä¸­çš„æ¯ä¸ªå…ƒç´ ï¼ˆå³ moving å’Œ fixed å›¾åƒï¼‰éƒ½è¢«ä¹˜ä»¥äº† factor=5ã€‚ä¼ é€’ç»™æ¨¡å‹çš„æ˜¯å·²ç»è¢«æ”¾å¤§çš„å›¾åƒã€‚

# å¯¹è¾“å…¥å›¾åƒè¿›è¡Œæ”¾å¤§
scaled_val_input = [f * factor for f in val_input]

# visualizeb
images = [img[0, :, :, 0] for img in scaled_val_input + list(val_pred)]
# val_input æ˜¯æœªè¢«æ”¾å¤§çš„åŸå§‹å›¾åƒï¼Œè€Œ list(val_pred) åŒ…å«äº†ç”±æ”¾å¤§åçš„å›¾åƒç”Ÿæˆçš„ moved å›¾åƒå’Œ flow åœºã€‚

titles = ['moving', 'fixed', 'moved', 'flow']
ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True)

# Registration of Brain MRI
# #############################################################################################################################################################
print("start registration of Brain MRI")
# ç°åœ¨æˆ‘ä»¬å°†é…å‡†ä¸€äº›æ›´æ¥è¿‘çœŸå®æƒ…å†µçš„æ•°æ®â€”â€”å¤§è„‘ MRI å›¾åƒã€‚ä¸ºäº†ä¾¿äºåœ¨æœ¬æ•™ç¨‹ä¸­è¿›è¡Œè®­ç»ƒå’Œé…å‡†ï¼Œæˆ‘ä»¬å°†é¦–å…ˆæå–å¤§è„‘æ‰«æå›¾åƒçš„ä¸­é—´åˆ‡ç‰‡ã€‚
# è¯·æ³¨æ„ï¼Œç”±äºæ­¤ä»»åŠ¡æ— æ³•æ•æ‰ç¬¬ä¸‰ç»´åº¦çš„å½¢å˜ï¼Œå› æ­¤æŸäº›å¯¹åº”å…³ç³»æ— æ³•å®Œå…¨å¯¹åº”ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæ­¤ç»ƒä¹ ä»å°†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ›´æ¥è¿‘çœŸå®æƒ…å†µçš„å¤æ‚å›¾åƒè¿›è¡Œé…å‡†ã€‚
# å¤§è„‘å·²ç»è¿‡å¼ºåº¦å½’ä¸€åŒ–ä»¿å°„å¯¹é½ï¼Œå¹¶ä½¿ç”¨ FreeSurfer å»é™¤é¢…éª¨ï¼Œä»¥ä¾¿èƒ½å¤Ÿä¸“æ³¨äºå¯å˜å½¢é…å‡†ã€‚
# download MRI tutorial data
# !wget https://surfer.nmr.mgh.harvard.edu/pub/data/voxelmorph/tutorial_data.tar.gz -O data.tar.gz
# !tar -xzvf data.tar.gz

import os
import urllib.request
import tarfile

# 1. è®¾ç½®ä¸‹è½½ URL å’Œæœ¬åœ°æ–‡ä»¶å
url = "https://surfer.nmr.mgh.harvard.edu/pub/data/voxelmorph/tutorial_data.tar.gz"
local_filename = "data.tar.gz"

# 2. å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™ä¸‹è½½
if not os.path.exists(local_filename):
    print(f"Downloading {url} ...")
    urllib.request.urlretrieve(url, local_filename)
    print(f"Downloaded to {local_filename}")
else:
    print(f"{local_filename} already exists. Skipping download.")

# 3. è§£å‹ tar.gz æ–‡ä»¶
extract_to = "."  # å½“å‰ç›®å½•ï¼Œå¯æ”¹ä¸º "data/" ç­‰
if not os.path.exists("tutorial_data"):
    print(f"Extracting {local_filename} to {extract_to} ...")
    with tarfile.open(local_filename, "r:gz") as tar:
        tar.extractall(path=extract_to)
    print("Extraction completed.")
else:
    print("tutorial_data/ already exists. Skipping extraction.")

